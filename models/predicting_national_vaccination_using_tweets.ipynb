{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting vaccination using tweets and government data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30 µs, sys: 2 µs, total: 32 µs\n",
      "Wall time: 38.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "import pandas as pd\n",
    "import geocoder\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "government_data_dir = './vaccine_data/hhs_data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def week_num_from_start_date(curr_date,start_date):\n",
    "    '''Returns the number of weeks from start date'''\n",
    "    date_delta = datetime.datetime.strptime(curr_date , '%Y_%m_%d') - start_date\n",
    "    return (date_delta.days//7+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "government_data_dir = './vaccine_data/hhs_data/'\n",
    "tweet_trends_weekly_output_dir = './tweet_trends/weekly_data'\n",
    "mined_trends_dir = 'mined_trends'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_years = ['2013','2014']\n",
    "dev_years = ['2015']\n",
    "test_years = ['2016','2017']\n",
    "\n",
    "train_download_dir = ('train',train_years)\n",
    "dev_download_dir = ('dev',dev_years)\n",
    "test_download_dir = ('test',test_years)\n",
    "data_split_ls = [train_download_dir,dev_download_dir,test_download_dir]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Weekly tweet trends df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_tweet_trends_weekly_csv(tweet_file_names,tweet_output_directory='./tweet_trends/weekly_data'):\n",
    "    '''Takes as input the tweets csv name to plots government trends against it '''\n",
    "    train_years = [2013,2014]\n",
    "    dev_years = [2015]\n",
    "    test_years = [2016,2017]\n",
    "    train_download_dir = ('train',train_years)\n",
    "    dev_download_dir = ('dev',dev_years)\n",
    "    test_download_dir = ('test',test_years)\n",
    "    data_split_ls = [train_download_dir,dev_download_dir,test_download_dir]\n",
    "\n",
    "    for tweet_file_name in tweet_file_names:\n",
    "        tweets_df = \\\n",
    "            pd.read_csv(tweet_file_name,index_col=['Unnamed: 0'])\n",
    "\n",
    "    os.makedirs(tweet_output_directory,exist_ok=True)\n",
    "    for data_split in data_split_ls:\n",
    "        split,years = data_split\n",
    "        for year in years:\n",
    "            government_data_df = pd.read_json(open(os.path.join(government_data_dir,split,str(year),'national.json')))\n",
    "            government_df_start_date = government_data_df.loc[0,'week_start']\n",
    "\n",
    "            government_df_start_date = datetime.datetime.strptime(\"{}_{}\".\\\n",
    "                                                                  format(year-1,government_df_start_date) , '%Y_%d%b')\n",
    "            \n",
    "            tweet_trends_dict = {}\n",
    "            for tweet_file_name in tweet_file_names:\n",
    "                tweets_df = pd.read_csv(tweet_file_name,index_col=['Unnamed: 0'])\n",
    "\n",
    "                curr_tweet_df = tweets_df[tweets_df['year'].isin([year-1,year])]\n",
    "                curr_tweet_df['week_number']=curr_tweet_df['date'].apply(lambda x: week_num_from_start_date(x,government_df_start_date))\n",
    "                curr_tweet_df=curr_tweet_df[(curr_tweet_df['week_number']>0) & (curr_tweet_df['week_number']<53)]\n",
    "                curr_tweet_df = curr_tweet_df.groupby('week_number',as_index=False)['count'].sum()\n",
    "                count_tweets_week= curr_tweet_df['count']\n",
    "                \n",
    "                tweet_trends_dict[tweet_file_name[13:-4]]=count_tweets_week\n",
    "            tweet_trends_df = pd.DataFrame(tweet_trends_dict)\n",
    "            tweet_trends_df.to_csv(\"{}/{}.csv\".format(tweet_output_directory,year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jawa/anaconda2/envs/eff_treat/lib/python3.6/site-packages/ipykernel/__main__.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "curr_files_list = os.listdir(mined_trends_dir)\n",
    "curr_files_list = [\"mined_trends/{}\".format(x) for x in curr_files_list if '.csv' in x]\n",
    "generate_tweet_trends_weekly_csv(curr_files_list,tweet_trends_weekly_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'train'\n",
    "train_years = ['2013','2014']\n",
    "#train_years = ['2014']\n",
    "train_download_dir = (split,train_years)\n",
    "\n",
    "X = []\n",
    "for year in train_years:\n",
    "    data_df = pd.read_json(open(os.path.join(government_data_dir,split,year,'national.json')))\n",
    "    X.append(data_df['percentage'].values)\n",
    "X = np.asarray(X)\n",
    "week_means = X.mean(axis = 0)\n",
    "\n",
    "threshold_start_pred  = 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in last train prediction 0.00022510474748241332 %\n"
     ]
    }
   ],
   "source": [
    "#train_years = ['2014']\n",
    "train_download_dir = ('train',train_years)\n",
    "split,years = train_download_dir\n",
    "government_threshold_start_pred  = 4\n",
    "tweet_threshold_start_pred = 4\n",
    "Y = []\n",
    "X = []\n",
    "for year in years:\n",
    "    government_data_df = pd.read_json(open(os.path.join(government_data_dir,split,year,'national.json')))\n",
    "    percent_vaccinated_week = (government_data_df['percentage']).values\n",
    "    percent_vaccinated_week = percent_vaccinated_week -  week_means\n",
    "    \n",
    "    tweet_weekly_df = pd.read_csv(open(os.path.join(tweet_trends_weekly_output_dir,\"{}.csv\".format(year))),index_col=['Unnamed: 0'])\n",
    "\n",
    "    initial_week_government_val = [percent_vaccinated_week[i] for i in range(0,government_threshold_start_pred)]\n",
    "    \n",
    "    inital_week_tweet_vals  = []\n",
    "    for i in range(0,tweet_threshold_start_pred):\n",
    "        inital_week_tweet_vals += list(tweet_weekly_df.loc[i].values)\n",
    "        \n",
    "    for i in range(threshold_start_pred,len(percent_vaccinated_week)):\n",
    "        X.append(initial_week_government_val+inital_week_tweet_vals)        \n",
    "        Y.append(percent_vaccinated_week[i])\n",
    "\n",
    "\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X,Y)\n",
    "y_pred = model.predict(X)\n",
    "error = metrics.mean_squared_error([y_pred[-1]],[Y[-1]])\n",
    "print(\"Error in last train prediction {} %\".format(error*100 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEV Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in dev train prediction 0.032246304565517005 %\n"
     ]
    }
   ],
   "source": [
    "split,years = dev_download_dir\n",
    "Y = []\n",
    "X = []\n",
    "for year in years:\n",
    "    government_data_df = pd.read_json(open(os.path.join(government_data_dir,split,year,'national.json')))\n",
    "    percent_vaccinated_week = (government_data_df['percentage']).values\n",
    "    percent_vaccinated_week = percent_vaccinated_week -  week_means\n",
    "    \n",
    "    tweet_weekly_df = pd.read_csv(open(os.path.join(tweet_trends_weekly_output_dir,\"{}.csv\".format(year))),index_col=['Unnamed: 0'])\n",
    "\n",
    "    initial_week_government_val = [percent_vaccinated_week[i] for i in range(0,government_threshold_start_pred)]\n",
    "    \n",
    "    inital_week_tweet_vals  = []\n",
    "    for i in range(0,tweet_threshold_start_pred):\n",
    "        inital_week_tweet_vals += list(tweet_weekly_df.loc[i].values)\n",
    "        \n",
    "    for i in range(threshold_start_pred,len(percent_vaccinated_week)):\n",
    "        X.append(initial_week_government_val+inital_week_tweet_vals)        \n",
    "        Y.append(percent_vaccinated_week[i])\n",
    "\n",
    "\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "y_pred = model.predict(X)\n",
    "error = metrics.mean_squared_error([y_pred[-1]],[Y[-1]])\n",
    "print(\"Error in dev train prediction {} %\".format(error*100 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in test prediction for year 2016 = 0.02859682623095311 %\n",
      "Error in test prediction for year 2017 = 0.15564644158487295 %\n"
     ]
    }
   ],
   "source": [
    "split,years = test_download_dir\n",
    "for year in years:\n",
    "    Y = []\n",
    "    X = []\n",
    "\n",
    "    government_data_df = pd.read_json(open(os.path.join(government_data_dir,split,year,'national.json')))\n",
    "    percent_vaccinated_week = (government_data_df['percentage']).values\n",
    "    percent_vaccinated_week = percent_vaccinated_week -  week_means[0:len(percent_vaccinated_week)]\n",
    "    \n",
    "    tweet_weekly_df = pd.read_csv(open(os.path.join(tweet_trends_weekly_output_dir,\"{}.csv\".format(year))),index_col=['Unnamed: 0'])\n",
    "\n",
    "    initial_week_government_val = [percent_vaccinated_week[i] for i in range(0,government_threshold_start_pred)]\n",
    "    \n",
    "    inital_week_tweet_vals  = []\n",
    "    for i in range(0,tweet_threshold_start_pred):\n",
    "        inital_week_tweet_vals += list(tweet_weekly_df.loc[i].values)\n",
    "        \n",
    "    for i in range(threshold_start_pred,len(percent_vaccinated_week)):\n",
    "        X.append(initial_week_government_val+inital_week_tweet_vals)\n",
    "        list(tweet_weekly_df.loc[i].values)\n",
    "        Y.append(percent_vaccinated_week[i])\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "    y_pred = model.predict(X)\n",
    "    error = metrics.mean_squared_error([y_pred[-1]],[Y[-1]])\n",
    "    print(\"Error in test prediction for year {} = {} %\".format(year, error*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Coeff [-4.10263935e-13 -8.37865640e-13 -9.51696650e-13 -4.35041049e-13\n",
      "  4.22266597e-08  6.38722584e-09  1.02905305e-08  1.20292753e-07\n",
      "  1.34841434e-08 -6.67110254e-08  8.87114700e-09 -2.94522080e-08\n",
      " -5.46462655e-08  1.31292976e-08  7.06143301e-08  2.69682869e-08\n",
      "  1.77422940e-08  1.41583506e-07  3.86782009e-08 -7.70015560e-08\n",
      "  1.84519858e-08 -9.58083876e-08 -1.71745406e-07  2.73231328e-08],\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Coeff {},\".format(model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:eff_treat]",
   "language": "python",
   "name": "conda-env-eff_treat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
