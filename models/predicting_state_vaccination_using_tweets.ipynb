{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting state vaccination using tweets and government data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geocoder\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def week_num_from_start_date(curr_date,start_date):\n",
    "    '''Returns the number of weeks from start date'''\n",
    "    date_delta = datetime.datetime.strptime(curr_date , '%Y_%m_%d') - start_date\n",
    "    return (date_delta.days//7+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "government_data_dir = './vaccine_data/hhs_data/'\n",
    "tweet_trends_weekly_output_dir = './tweet_trends/weekly_data'\n",
    "mined_trends_dir = 'mined_trends'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_years = ['2013','2014']\n",
    "dev_years = ['2015']\n",
    "test_years = ['2016','2017']\n",
    "\n",
    "train_download_dir = ('train',train_years)\n",
    "dev_download_dir = ('dev',dev_years)\n",
    "test_download_dir = ('test',test_years)\n",
    "data_split_ls = [train_download_dir,dev_download_dir,test_download_dir]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Tweets for National, CA and  NY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tweet_trends_weekly_csv(tweet_file_names,\\\n",
    "                                     tweet_output_directory='./tweet_trends/weekly_data',state = 'National'):\n",
    "    '''Takes as input the tweets csv name to plots government trends against it '''\n",
    "    train_years = [2013,2014]\n",
    "    dev_years = [2015]\n",
    "    test_years = [2016,2017]\n",
    "    train_download_dir = ('train',train_years)\n",
    "    dev_download_dir = ('dev',dev_years)\n",
    "    test_download_dir = ('test',test_years)\n",
    "    data_split_ls = [train_download_dir,dev_download_dir,test_download_dir]\n",
    "\n",
    "    for tweet_file_name in tweet_file_names:\n",
    "        tweets_df = \\\n",
    "            pd.read_csv(tweet_file_name,index_col=['Unnamed: 0'])\n",
    "\n",
    "    os.makedirs(tweet_output_directory,exist_ok=True)\n",
    "    for data_split in data_split_ls:\n",
    "        split,years = data_split\n",
    "        for year in years:\n",
    "            government_data_df = pd.read_json(open(os.path.join(government_data_dir,split,str(year),'national.json')))\n",
    "            government_df_start_date = government_data_df.loc[0,'week_start']\n",
    "\n",
    "            government_df_start_date = datetime.datetime.strptime(\"{}_{}\".\\\n",
    "                                                                  format(year-1,government_df_start_date) , '%Y_%d%b')\n",
    "            tweet_trends_dict = {}\n",
    "            for tweet_file_name in tweet_file_names:\n",
    "                tweets_df = pd.read_csv(tweet_file_name,index_col=['Unnamed: 0'])\n",
    "\n",
    "                curr_tweet_df = tweets_df[tweets_df['year'].isin([year-1,year])]\n",
    "                curr_tweet_df['week_number']=curr_tweet_df['date'].apply(lambda x: week_num_from_start_date(x,government_df_start_date))\n",
    "                curr_tweet_df=curr_tweet_df[(curr_tweet_df['week_number']>0) & (curr_tweet_df['week_number']<53)]\n",
    "                if state is not 'national':\n",
    "                    curr_tweet_df=curr_tweet_df[curr_tweet_df['state']==state]\n",
    "                        \n",
    "                curr_tweet_df = curr_tweet_df.groupby('week_number',as_index=False)['count'].sum()\n",
    "                count_tweets_week= curr_tweet_df['count']\n",
    "                tweet_trends_dict[tweet_file_name[13:-4]]=count_tweets_week\n",
    "            \n",
    "            tweet_trends_df = pd.DataFrame(tweet_trends_dict)\n",
    "            tweet_trends_df.to_csv(\"{}/{}_{}.csv\".format(tweet_output_directory,state,year))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "states = ['national','California','New York']\n",
    "curr_files_list = os.listdir(mined_trends_dir)\n",
    "curr_files_list = [\"mined_trends/{}\".format(x) for x in curr_files_list if '.csv' in x]\n",
    "for state in states:\n",
    "    generate_tweet_trends_weekly_csv(curr_files_list,tweet_trends_weekly_output_dir,state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_data_split(week_means,state,state_code,split,years,tweet_threshold_start_pred,government_threshold_start_pred):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for year in years:\n",
    "        government_data_df = pd.read_json(open(os.path.join(government_data_dir,split,year,\"{}.json\".format(state_code))))\n",
    "        percent_vaccinated_week = (government_data_df['percentage']).values\n",
    "        percent_vaccinated_week = percent_vaccinated_week -  week_means[0:len(percent_vaccinated_week)]\n",
    "\n",
    "        tweet_weekly_df = pd.read_csv(open(os.path.join(tweet_trends_weekly_output_dir,\"{}_{}.csv\".format(state,year))),index_col=['Unnamed: 0'])\n",
    "\n",
    "        initial_week_government_val = [percent_vaccinated_week[i] for i in range(0,government_threshold_start_pred)]\n",
    "\n",
    "        inital_week_tweet_vals  = []\n",
    "        for i in range(0,tweet_threshold_start_pred):\n",
    "            inital_week_tweet_vals += list(tweet_weekly_df.loc[i].values)\n",
    "\n",
    "        for i in range(government_threshold_start_pred,len(percent_vaccinated_week)):\n",
    "            X.append(initial_week_government_val+inital_week_tweet_vals)        \n",
    "            Y.append(percent_vaccinated_week[i])\n",
    "        \n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Curr State national national\n",
      "--------------------\n",
      "Error in train prediction 0.00020345575271005283 %\n",
      "Error in dev train prediction 0.032536767143358895 %\n",
      "Error in test prediction for year 2016 = 0.029141779701367027 %\n",
      "Error in test prediction for year 2017 = 0.1550957022476945 %\n",
      "--------------------\n",
      "Curr State California CA\n",
      "--------------------\n",
      "Error in train prediction 0.0006584484300624913 %\n",
      "Error in dev train prediction 0.12108231351020352 %\n",
      "Error in test prediction for year 2016 = 0.1996042301816189 %\n",
      "Error in test prediction for year 2017 = 0.14736626917396864 %\n",
      "--------------------\n",
      "Curr State New York NY\n",
      "--------------------\n",
      "Error in train prediction 3.521668300791518e-05 %\n",
      "Error in dev train prediction 0.024871267475208365 %\n",
      "Error in test prediction for year 2016 = 0.018327242709688187 %\n",
      "Error in test prediction for year 2017 = 0.16696746958582148 %\n"
     ]
    }
   ],
   "source": [
    "tweet_threshold_start_pred = 4 \n",
    "govt_threshold_start_pred = 4\n",
    "\n",
    "for state_code,state  in [ ('national','national'),('CA', 'California'),('NY','New York')]:\n",
    "    print(\"-\"*20)\n",
    "    print(\"Curr State {} {}\".format(state,state_code))\n",
    "    print(\"-\"*20)\n",
    "\n",
    "    split,years = train_download_dir\n",
    "    X = []\n",
    "    for year in train_years:\n",
    "        data_df = pd.read_json(open(os.path.join(government_data_dir,split,year,'{}.json'.format(state_code))))\n",
    "        X.append(data_df['percentage'].values)\n",
    "    X = np.asarray(X)\n",
    "    week_means = X.mean(axis = 0)\n",
    "\n",
    "    X,Y = return_data_split(week_means,state,state_code,split,years,tweet_threshold_start_pred,govt_threshold_start_pred)\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X,Y)\n",
    "\n",
    "    y_pred = model.predict(X)\n",
    "    error = metrics.mean_squared_error([y_pred[-1]],[Y[-1]])\n",
    "    print(\"Error in train prediction {} %\".format(error*100 ))\n",
    "\n",
    "    # DEV Prediction\n",
    "\n",
    "    split,years = dev_download_dir\n",
    "    X,Y = return_data_split(week_means,state,state_code,split,years,tweet_threshold_start_pred,govt_threshold_start_pred)\n",
    "    y_pred = model.predict(X)\n",
    "    error = metrics.mean_squared_error([y_pred[-1]],[Y[-1]])\n",
    "    print(\"Error in dev train prediction {} %\".format(error*100 ))\n",
    "\n",
    "    split,years = test_download_dir\n",
    "    for year in years:\n",
    "        X,Y = return_data_split(week_means,state,state_code,split,[year],tweet_threshold_start_pred,govt_threshold_start_pred)\n",
    "        y_pred = model.predict(X)\n",
    "        error = metrics.mean_squared_error([y_pred[-1]],[Y[-1]])\n",
    "        print(\"Error in test prediction for year {} = {} %\".format(year, error*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:eff_treat]",
   "language": "python",
   "name": "conda-env-eff_treat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
